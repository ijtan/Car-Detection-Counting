{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import cv2\n",
    "import torch\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_path = 'inputs/media/Clips/'\n",
    "output_txt_path = 'outputs/yolo5_classification/'\n",
    "custom_model = False\n",
    "# custom_model = True\n",
    "\n",
    "def get_video_paths():\n",
    "    \"\"\"\n",
    "    Recursively Returns a list of all the videos in the directory\n",
    "    \"\"\"\n",
    "    return [str(p) for p in Path.rglob(Path(video_path), '*.mp4')]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://github.com/ultralytics/yolov5/archive/master.zip\" to C:\\Users\\ethan/.cache\\torch\\hub\\master.zip\n",
      "YOLOv5  2022-1-12 torch 1.10.1 CUDA:0 (NVIDIA GeForce RTX 2060, 6144MiB)\n",
      "\n",
      "Fusing layers... \n",
      "Model Summary: 213 layers, 7023610 parameters, 0 gradients, 15.8 GFLOPs\n",
      "Adding AutoShape... \n"
     ]
    }
   ],
   "source": [
    "model = None\n",
    "if custom_model:\n",
    "    output_txt_path = output_txt_path.replace('yolo5_classification', 'yolo5_classification_Ours')\n",
    "    custom_model_path = 'custom_train\\\\yolov5\\\\runs\\\\train\\\\exp42\\weights\\\\best.pt'\n",
    "    model = torch.hub.load('ultralytics/yolov5', 'custom', path=custom_model_path, force_reload=True)\n",
    "else:\n",
    "    model = torch.hub.load('ultralytics/yolov5', 'yolov5m', force_reload=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'outputs/yolo5_classification_Ours/'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_txt_path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_image(img):\n",
    "    results = model([img])\n",
    "    return results\n",
    "\n",
    "\n",
    "def classify_images(images):\n",
    "    results = model(images)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_yolo(x1, y1, x2, y2,sizes):\n",
    "    x_center = (x1 + x2) / 2\n",
    "    y_center = (y1 + y2) / 2\n",
    "    width = x2 - x1\n",
    "    height = y2 - y1\n",
    "\n",
    "    img_height, img_width = sizes\n",
    "    # normalize\n",
    "    x_center = x_center / img_width\n",
    "    y_center = y_center / img_height\n",
    "    width = width / img_width\n",
    "    height = height / img_height\n",
    "\n",
    "\n",
    "    return x_center, y_center, width, height\n",
    "\n",
    "def convert_to_minmax(x_center, y_center, width, height, sizes):\n",
    "    img_height, img_width = sizes\n",
    "    # normalize\n",
    "    x_center = x_center * img_width\n",
    "    y_center = y_center * img_height\n",
    "    width = width * img_width\n",
    "    height = height * img_height\n",
    "\n",
    "    x1 = x_center - width/2\n",
    "    y1 = y_center - height/2\n",
    "    x2 = x_center + width/2\n",
    "    y2 = y_center + height/2\n",
    "\n",
    "    # round\n",
    "    x1 = round(x1)\n",
    "    y1 = round(y1)\n",
    "    x2 = round(x2)\n",
    "    y2 = round(y2)\n",
    "\n",
    "    return x1, y1, x2, y2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = ['car', 'motorbike', 'truck', 'priority', 'bus']\n",
    "coco_names = []\n",
    "with open('inputs/weights/coco.names', 'r') as f:\n",
    "    for line in f:\n",
    "        coco_names.append(line.strip().lower())\n",
    "\n",
    "coco_ours_map = {}\n",
    "for c in classes:\n",
    "    if c in coco_names:\n",
    "        coco_ours_map[c] = classes.index(c)\n",
    "\n",
    "\n",
    "def append_box_to_file(path, frame_no, results, sizes):\n",
    "    results = results.pandas().xyxy[0]\n",
    "    str_to_append = \"\"\n",
    "    for i, row in results.iterrows():\n",
    "        x1, y1, x2, y2 = row['xmin'], row['ymin'], row['xmax'], row['ymax']\n",
    "\n",
    "\n",
    "        x_center, y_center, width, height = convert_to_yolo(x1, y1, x2, y2, sizes)\n",
    "        \n",
    "\n",
    "        conf, clas_id, name = row['confidence'], row['class'], row['name']\n",
    "\n",
    "        if name not in coco_ours_map:\n",
    "            continue\n",
    "\n",
    "        our_class_id = coco_ours_map[name]\n",
    "        # str_to_append  += str(our_class_id) + ' ' + str(x1) + ' ' + str(y1) + ' ' + str(x2) + ' ' + str(y2) + '\\n'\n",
    "        str_to_append += str(our_class_id) + ' ' + str(x_center) + ' ' + str(y_center) + ' ' + str(width) + ' ' + str(height) + '\\n'\n",
    "\n",
    "    # print('Saving Frame: ', frame_no)\n",
    "    new_path=os.path.join(path, str(frame_no).zfill(4)+'.txt')\n",
    "    new_path = new_path.replace('.mp4', '')\n",
    "\n",
    "    # create if not exists\n",
    "    if not os.path.exists(new_path):\n",
    "        # if subdirs do not exist, create aswell\n",
    "        if not os.path.exists(os.path.dirname(new_path)):\n",
    "            os.makedirs(os.path.dirname(new_path))\n",
    "\n",
    "    with open(new_path, 'w') as f:\n",
    "        f.write(str_to_append)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_image(img, results):\n",
    "    results = results.pandas().xyxy[0]\n",
    "    for i, row in results.iterrows():\n",
    "        x1, y1, x2, y2 = row['xmin'], row['ymin'], row['xmax'], row['ymax']\n",
    "        x1 = round(x1)\n",
    "        y1 = round(y1)\n",
    "        x2 = round(x2)\n",
    "        y2 = round(y2)\n",
    "\n",
    "        size = img.shape[:2]\n",
    "        x1, y1, x2, y2 = convert_to_minmax(*convert_to_yolo(*(x1, y1, x2, y2), size),size)\n",
    "        \n",
    "        conf,clas_id,name = row['confidence'], row['class'], row['name']\n",
    "        cv2.rectangle(img, (x1, y1), (x2, y2), (255, 0, 0), 2)\n",
    "        cv2.putText(img, name, (x1, y1),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2)\n",
    "    return img\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_videos(videos, show_video=False, save=False):\n",
    "    for video_path in videos:\n",
    "        total_frames = cv2.VideoCapture(video_path).get(cv2.CAP_PROP_FRAME_COUNT)\n",
    "        video = cv2.VideoCapture(video_path)\n",
    "\n",
    "\n",
    "        video_name = video_path.split('/')[-1]\n",
    "        coord_path = os.path.join(output_txt_path, video_name)\n",
    "\n",
    "        print('Labelling video: {}'.format(video_name))\n",
    "\n",
    "        labelled_frames = []\n",
    "        while True:\n",
    "            _, frame = video.read()\n",
    "            if frame is None:\n",
    "                break\n",
    "\n",
    "            frame_no = video.get(cv2.CAP_PROP_POS_FRAMES)\n",
    "            print(f'Frame: {frame_no}/{total_frames}',end='\\r')\n",
    "            result = classify_image(frame)\n",
    "\n",
    "            if save:\n",
    "                size = frame.shape[:2]\n",
    "                append_box_to_file(coord_path, int(frame_no), result, size)\n",
    "\n",
    "            if show_video:\n",
    "                img = draw_image(frame, result)\n",
    "                cv2.imshow('frame', img)\n",
    "                if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "                    break\n",
    "        print('\\n')\n",
    "        video.release()\n",
    "        cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 24 total videos\n",
      "Labelling video: inputs\\media\\Clips\\Background\\Test\\Day_1.mp4\n",
      "Frame: 467.0/467.0\n",
      "\n",
      "Labelling video: inputs\\media\\Clips\\Background\\Test\\Day_2.mp4\n",
      "Frame: 317.0/317.0\n",
      "\n",
      "Labelling video: inputs\\media\\Clips\\Background\\Test\\Dry.mp4\n",
      "Frame: 324.0/324.0\n",
      "\n",
      "Labelling video: inputs\\media\\Clips\\Background\\Test\\Night_1.mp4\n",
      "Frame: 306.0/306.0\n",
      "\n",
      "Labelling video: inputs\\media\\Clips\\Background\\Test\\Night_2.mp4\n",
      "Frame: 321.0/321.0\n",
      "\n",
      "Labelling video: inputs\\media\\Clips\\Background\\Test\\Rain_1.mp4\n",
      "Frame: 314.0/314.0\n",
      "\n",
      "Labelling video: inputs\\media\\Clips\\Background\\Test\\Wet_Bright.mp4\n",
      "Frame: 325.0/325.0\n",
      "\n",
      "Labelling video: inputs\\media\\Clips\\Background\\Test\\Wet_Dim.mp4\n",
      "Frame: 317.0/317.0\n",
      "\n",
      "Labelling video: inputs\\media\\Clips\\Foreground\\Test\\Day_1.mp4\n",
      "Frame: 467.0/467.0\n",
      "\n",
      "Labelling video: inputs\\media\\Clips\\Foreground\\Test\\Day_2.mp4\n",
      "Frame: 317.0/317.0\n",
      "\n",
      "Labelling video: inputs\\media\\Clips\\Foreground\\Test\\Dry.mp4\n",
      "Frame: 324.0/324.0\n",
      "\n",
      "Labelling video: inputs\\media\\Clips\\Foreground\\Test\\Night_1.mp4\n",
      "Frame: 306.0/306.0\n",
      "\n",
      "Labelling video: inputs\\media\\Clips\\Foreground\\Test\\Night_2.mp4\n",
      "Frame: 321.0/321.0\n",
      "\n",
      "Labelling video: inputs\\media\\Clips\\Foreground\\Test\\Rain_1.mp4\n",
      "Frame: 314.0/314.0\n",
      "\n",
      "Labelling video: inputs\\media\\Clips\\Foreground\\Test\\Wet_Bright.mp4\n",
      "Frame: 325.0/325.0\n",
      "\n",
      "Labelling video: inputs\\media\\Clips\\Foreground\\Test\\Wet_Dim.mp4\n",
      "Frame: 317.0/317.0\n",
      "\n",
      "Labelling video: inputs\\media\\Clips\\Original\\Test\\Day_1.mp4\n",
      "Frame: 467.0/467.0\n",
      "\n",
      "Labelling video: inputs\\media\\Clips\\Original\\Test\\Day_2.mp4\n",
      "Frame: 317.0/317.0\n",
      "\n",
      "Labelling video: inputs\\media\\Clips\\Original\\Test\\Dry.mp4\n",
      "Frame: 324.0/324.0\n",
      "\n",
      "Labelling video: inputs\\media\\Clips\\Original\\Test\\Night_1.mp4\n",
      "Frame: 306.0/306.0\n",
      "\n",
      "Labelling video: inputs\\media\\Clips\\Original\\Test\\Night_2.mp4\n",
      "Frame: 321.0/321.0\n",
      "\n",
      "Labelling video: inputs\\media\\Clips\\Original\\Test\\Rain_1.mp4\n",
      "Frame: 314.0/314.0\n",
      "\n",
      "Labelling video: inputs\\media\\Clips\\Original\\Test\\Wet_Bright.mp4\n",
      "Frame: 325.0/325.0\n",
      "\n",
      "Labelling video: inputs\\media\\Clips\\Original\\Test\\Wet_Dim.mp4\n",
      "Frame: 317.0/317.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "videos = get_video_paths()\n",
    "# videos = [v for v in videos if 'original' in v.lower()]\n",
    "videos = [v for v in videos if 'test' in v.lower()]\n",
    "print('Found {} total videos'.format(len(videos)))\n",
    "\n",
    "label_videos(videos, show_video=False,save=True)\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "bda7da3f1f17f53873a773ca7f2ed74b2eb6ac96c2af17f2f610b1874751e508"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('CV': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
