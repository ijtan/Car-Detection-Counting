{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import cv2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_input_path = 'inputs/media/Clips/'\n",
    "videos = Path(video_input_path).rglob('*.mp4')\n",
    "videos = [str(v) for v in videos]\n",
    "# videos = [v for v in videos if 'msida' in v]\n",
    "videos = [v for v in videos if 'original' in v.lower()]\n",
    "# videos = [v for v in videos if 'test' in v.lower()]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_yolo(x1, y1, x2, y2, sizes):\n",
    "    x_center = (x1 + x2) / 2\n",
    "    y_center = (y1 + y2) / 2\n",
    "    width = x2 - x1\n",
    "    height = y2 - y1\n",
    "\n",
    "    img_height, img_width = sizes\n",
    "    # normalize\n",
    "    x_center = x_center / img_width\n",
    "    y_center = y_center / img_height\n",
    "    width = width / img_width\n",
    "    height = height / img_height\n",
    "\n",
    "    return x_center, y_center, width, height\n",
    "\n",
    "\n",
    "def convert_to_minmax(x_center, y_center, width, height, sizes):\n",
    "    img_height, img_width = sizes\n",
    "    # normalize\n",
    "    x_center = x_center * img_width\n",
    "    y_center = y_center * img_height\n",
    "    width = width * img_width\n",
    "    height = height * img_height\n",
    "\n",
    "    x1 = x_center - width/2\n",
    "    y1 = y_center - height/2\n",
    "    x2 = x_center + width/2\n",
    "    y2 = y_center + height/2\n",
    "\n",
    "    # round\n",
    "    x1 = round(x1)\n",
    "    y1 = round(y1)\n",
    "    x2 = round(x2)\n",
    "    y2 = round(y2)\n",
    "\n",
    "    return x1, y1, x2, y2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # annotations_path = 'outputs/yolo5_classification_ours/'\n",
    "# annotations_path = 'outputs/yolo5_classification/'\n",
    "# annotation_paths = Path(annotations_path).rglob('*.txt')\n",
    "# annotation_paths = [str(a) for a in annotation_paths]\n",
    "# # annotation_paths = [a for a in annotation_paths if 'test' in a.lower()]\n",
    "# annotation_paths\n",
    "\n",
    "# assert len(annotation_paths) != 0, 'No annotations found'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "annotation_choice = 'ourYolo'\n",
    "# annotation_choice = 'ogYolo'\n",
    "# annotation_choice = 'ground_truth'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "if annotation_choice == 'ourYolo':\n",
    "    annotations_path = 'outputs/yolo5_classification_ours/'\n",
    "    annotation_paths = Path(annotations_path).rglob('*.txt')\n",
    "    annotation_paths = [str(a) for a in annotation_paths]\n",
    "    annotation_paths = [a for a in annotation_paths if 'original' in a.lower()] # remove background and fg\n",
    "\n",
    "elif annotation_choice == 'ground_truth':\n",
    "    annotations_path = 'inputs/annotations/'\n",
    "    annotation_paths = Path(annotations_path).rglob('*.txt')\n",
    "    annotation_paths = [str(a) for a in annotation_paths]\n",
    "    # annotation_paths = [a for a in annotation_paths if 'original' in a.lower()] #no og in ground truth\n",
    "    \n",
    "elif annotation_choice == 'ogYolo':\n",
    "    annotations_path = 'outputs/yolo5_classification/'\n",
    "    annotation_paths = Path(annotations_path).rglob('*.txt')\n",
    "    annotation_paths = [str(a) for a in annotation_paths]\n",
    "    annotation_paths = [a for a in annotation_paths if 'original' in a.lower()] # remove background and fg\n",
    "\n",
    "\n",
    "assert len(annotation_paths) != 0, 'No annotations found'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_centroid(x1, y1, x2, y2):\n",
    "    x_center = (x1 + x2) / 2\n",
    "    y_center = (y1 + y2) / 2\n",
    "    return round(x_center), round(y_center)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def centroid_distance(x1,y1,x2,y2):\n",
    "    return np.sqrt((x1-x2)**2 + (y1-y2)**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "draw_bounding_boxes = True\n",
    "draw_centroids = True\n",
    "draw_mid_line = True    \n",
    "draw_counts = True      # draw counts of cards\n",
    "vis = True              #visualize everything \n",
    "save_video = False\n",
    "\n",
    "abandoned_patience = 20 # how many frames to wait before centroid deleted\n",
    "minimum_distance = 60   # distance to consider two centroids (in consecutive frames) the same\n",
    "x_cutoff = 0.5          # line = x_res * this\n",
    "y_cutoff = 0.5          \n",
    "frameTime = 1           # delay between frames = how fast video showing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "abandoned_objects = {}\n",
    "def updateAbandoned(old_centroid_locations, object_locations):\n",
    "    # copy object_locations\n",
    "    object_locations_copy = object_locations.copy()\n",
    "    for ix, c in old_centroid_locations.items():\n",
    "        new_centroid = object_locations_copy[ix]\n",
    "        if new_centroid == old_centroid_locations[ix]:\n",
    "                if ix in abandoned_objects:\n",
    "                    abandoned_objects[ix] += 1\n",
    "                else:\n",
    "                    abandoned_objects[ix] = 1\n",
    "        else:\n",
    "            if ix in abandoned_objects:\n",
    "                abandoned_objects[ix] = 0\n",
    "            else:\n",
    "                abandoned_objects[ix] = 0\n",
    "    \n",
    "    for k, v in dict(abandoned_objects).items():\n",
    "        if v > abandoned_patience:\n",
    "            # print('Abandoned object:', k)\n",
    "            del abandoned_objects[k]\n",
    "            del object_locations[k]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "prev_total_count = 0\n",
    "def draw(frame, object_locations, left_right, right_left):\n",
    "    global prev_total_count\n",
    "    mid_x = round(frame.shape[1] * x_cutoff)\n",
    "    mid_y = round(frame.shape[0] * y_cutoff)\n",
    "    if vis:\n",
    "        # cv2 show centroids\n",
    "        if draw_centroids:\n",
    "            for id, c in object_locations.items():\n",
    "                cv2.circle(frame, (c[0], c[1]), 5, (0, 0, 255), -1)\n",
    "\n",
    "        if draw_counts:\n",
    "            # show right_left on left of frame\n",
    "            cv2.putText(frame, f'{right_left}', (100, 100),cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)\n",
    "\n",
    "            # show left_right on right of frame\n",
    "            cv2.putText(frame, f'{left_right}', (frame.shape[1] - 100, 100), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)\n",
    "\n",
    "            total_count = left_right + right_left\n",
    "            \n",
    "            # show total centred X\n",
    "            cv2.putText(frame, f'{total_count}', (frame.shape[1]//2, 100), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)\n",
    "\n",
    "        # draw vertical line in middle\n",
    "        if draw_mid_line:\n",
    "            if prev_total_count != total_count:\n",
    "                cv2.line(frame, (mid_x, 0), (mid_x, frame.shape[0]), (0, 0, 255), 2)\n",
    "            else:\n",
    "                cv2.line(frame, (round(frame.shape[1]*x_cutoff), 0), (round(frame.shape[1]*x_cutoff), frame.shape[0]), (0, 255, 0), 2)\n",
    "\n",
    "        prev_total_count = total_count\n",
    "        cv2.imshow('frame', frame)\n",
    "        if cv2.waitKey(frameTime) & 0xFF == ord('q'):\n",
    "            return False\n",
    "    return True, frame\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def updateCentroids(frame, object_locations, curr_centroids, left_right, right_left):\n",
    "    mid_x = round(frame.shape[1] * x_cutoff)\n",
    "    mid_y = round(frame.shape[0] * y_cutoff)\n",
    "         # match new centroids with old\n",
    "    old_centroid_locations = {k: v for k, v in object_locations.items()}\n",
    "    for ix, c in enumerate(curr_centroids):\n",
    "        if len(object_locations) == 0:\n",
    "            object_locations[ix] = c\n",
    "        else:\n",
    "            keys = list(object_locations.keys())\n",
    "            next_key = max(keys) + 1\n",
    "            min_centroid = next_key\n",
    "            for id, o in object_locations.items():\n",
    "                dist = centroid_distance(o[0], o[1], c[0], c[1])\n",
    "                min_dist = minimum_distance\n",
    "                if dist < min_dist:\n",
    "                    min_dist = dist\n",
    "                    min_centroid = id\n",
    "\n",
    "            if min_centroid != next_key:\n",
    "                old_centroid = object_locations[min_centroid]\n",
    "                if old_centroid[0] <= mid_x:\n",
    "                    if c[0] > mid_x:\n",
    "                        left_right += 1\n",
    "                elif old_centroid[0] >= mid_x:\n",
    "                    if c[0] < mid_x:\n",
    "                        right_left += 1\n",
    "\n",
    "            object_locations[min_centroid] = c\n",
    "    \n",
    "    return old_centroid_locations, object_locations, left_right, right_left\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getCentroids(annotations):\n",
    "    curr_centroids = []\n",
    "    for a in annotations:\n",
    "        a = a.split(' ')\n",
    "        a = [float(x) for x in a]\n",
    "        class_id = a[0]\n",
    "        a = a[1:]\n",
    "        x, y, w, h = a[0], a[1], a[2], a[3]\n",
    "        x1, y1, x2, y2 = convert_to_minmax(\n",
    "            x, y, w, h, (frame.shape[0], frame.shape[1]))\n",
    "        curr_centroids.append(find_centroid(x1, y1, x2, y2))\n",
    "\n",
    "        if vis and draw_bounding_boxes:\n",
    "                cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "\n",
    "    return curr_centroids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video: Day_1 Frames: 467 Annotations: 467\n",
      "Video: Day_2 Frames: 317 Annotations: 317\n",
      "Video: Dry Frames: 324 Annotations: 324\n",
      "Video: Night_1 Frames: 306 Annotations: 306\n",
      "Video: Night_2 Frames: 321 Annotations: 321\n",
      "Video: Rain_1 Frames: 314 Annotations: 314\n",
      "Video: Wet_Bright Frames: 325 Annotations: 325\n",
      "Video: Wet_Dim Frames: 317 Annotations: 317\n"
     ]
    }
   ],
   "source": [
    "for v in videos:\n",
    "    object_locations = {}\n",
    "    abandoned_objects = {}\n",
    "    left_right = 0\n",
    "    right_left = 0\n",
    "    \n",
    "    \n",
    "    video = cv2.VideoCapture(v)\n",
    "    video_name = v.split('\\\\')[-1].split('.')[0]\n",
    "    set = 'Test' if 'test' in v.lower() else 'Train'\n",
    "    annotation_files = [a for a in annotation_paths if video_name.lower() in a.lower()]\n",
    "    annotation_files = [a for a in annotation_files if set.lower() in a.lower()]\n",
    "    sorted_annotation_files = sorted(annotation_files, key=lambda x: x.rsplit('.')[-2])\n",
    "\n",
    "\n",
    "    if save_video:\n",
    "        fourcc = cv2.VideoWriter_fourcc(*'XVID')\n",
    "        out = cv2.VideoWriter(f'{video_name}_{set}.avi', fourcc, 30.0, (round(video.get(3)), round(video.get(4))))\n",
    "\n",
    "    print(f'Video: {video_name} Frames: {int(video.get(cv2.CAP_PROP_FRAME_COUNT))} Annotations: {len(annotation_files)}')\n",
    "    while True:\n",
    "        ret, frame = video.read()\n",
    "        if not ret:\n",
    "            break\n",
    "       \n",
    "\n",
    "        curr_frame = int(video.get(cv2.CAP_PROP_POS_FRAMES))\n",
    "\n",
    "\n",
    "        annotation_file = annotation_files[curr_frame-1]\n",
    "        annotations = open(annotation_file, 'r')\n",
    "        annotations = annotations.readlines()\n",
    "        annotations = [a.strip() for a in annotations]\n",
    "\n",
    "        curr_centroids = getCentroids(annotations)\n",
    "        old_centroid_locations, object_locations, left_right, right_left = updateCentroids(frame, object_locations, curr_centroids, left_right, right_left)\n",
    "        updateAbandoned(old_centroid_locations, object_locations)\n",
    "        toContinue, drawn_frame = draw(frame, object_locations, left_right, right_left)\n",
    "        if save_video:\n",
    "            out.write(drawn_frame)\n",
    "        if not toContinue:\n",
    "            break\n",
    "        \n",
    "\n",
    "    cv2.destroyAllWindows()\n",
    "    video.release()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "bda7da3f1f17f53873a773ca7f2ed74b2eb6ac96c2af17f2f610b1874751e508"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('CV': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
