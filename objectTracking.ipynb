{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import cv2\n",
    "import numpy as np\n",
    "import json\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_input_path = 'inputs/media/Clips/'\n",
    "videos = Path(video_input_path).rglob('*.mp4')\n",
    "videos = [str(v) for v in videos]\n",
    "# videos = [v for v in videos if 'msida' in v]\n",
    "videos = [v for v in videos if 'original' in v.lower()]\n",
    "# videos = [v for v in videos if 'test' in v.lower()]\n",
    "\n",
    "count_output_path = 'outputs/counting/'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_yolo(x1, y1, x2, y2, sizes):\n",
    "    x_center = (x1 + x2) / 2\n",
    "    y_center = (y1 + y2) / 2\n",
    "    width = x2 - x1\n",
    "    height = y2 - y1\n",
    "\n",
    "    img_height, img_width = sizes\n",
    "    # normalize\n",
    "    x_center = x_center / img_width\n",
    "    y_center = y_center / img_height\n",
    "    width = width / img_width\n",
    "    height = height / img_height\n",
    "\n",
    "    return x_center, y_center, width, height\n",
    "\n",
    "\n",
    "def convert_to_minmax(x_center, y_center, width, height, sizes):\n",
    "    img_height, img_width = sizes\n",
    "    # normalize\n",
    "    x_center = x_center * img_width\n",
    "    y_center = y_center * img_height\n",
    "    width = width * img_width\n",
    "    height = height * img_height\n",
    "\n",
    "    x1 = x_center - width/2\n",
    "    y1 = y_center - height/2\n",
    "    x2 = x_center + width/2\n",
    "    y2 = y_center + height/2\n",
    "\n",
    "    # round\n",
    "    x1 = round(x1)\n",
    "    y1 = round(y1)\n",
    "    x2 = round(x2)\n",
    "    y2 = round(y2)\n",
    "\n",
    "    return x1, y1, x2, y2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # annotations_path = 'outputs/yolo5_classification_ours/'\n",
    "# annotations_path = 'outputs/yolo5_classification/'\n",
    "# annotation_paths = Path(annotations_path).rglob('*.txt')\n",
    "# annotation_paths = [str(a) for a in annotation_paths]\n",
    "# # annotation_paths = [a for a in annotation_paths if 'test' in a.lower()]\n",
    "# annotation_paths\n",
    "\n",
    "# assert len(annotation_paths) != 0, 'No annotations found'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# annotation_choice = 'ourYolo'\n",
    "# annotation_choice = 'ogYolo'\n",
    "annotation_choice = 'ground_truth'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "if annotation_choice == 'ourYolo':\n",
    "    annotations_path = 'outputs/yolo5_classification_ours/'\n",
    "    annotation_paths = Path(annotations_path).rglob('*.txt')\n",
    "    annotation_paths = [str(a) for a in annotation_paths]\n",
    "    annotation_paths = [a for a in annotation_paths if 'original' in a.lower()] # remove background and fg\n",
    "\n",
    "elif annotation_choice == 'ground_truth':\n",
    "    annotations_path = 'inputs/annotations/'\n",
    "    annotation_paths = Path(annotations_path).rglob('*.txt')\n",
    "    annotation_paths = [str(a) for a in annotation_paths]\n",
    "    # annotation_paths = [a for a in annotation_paths if 'original' in a.lower()] #no og in ground truth\n",
    "    \n",
    "elif annotation_choice == 'ogYolo':\n",
    "    annotations_path = 'outputs/yolo5_classification/'\n",
    "    annotation_paths = Path(annotations_path).rglob('*.txt')\n",
    "    annotation_paths = [str(a) for a in annotation_paths]\n",
    "    annotation_paths = [a for a in annotation_paths if 'original' in a.lower()] # remove background and fg\n",
    "\n",
    "\n",
    "assert len(annotation_paths) != 0, 'No annotations found'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_centroid(x1, y1, x2, y2):\n",
    "    x_center = (x1 + x2) / 2\n",
    "    y_center = (y1 + y2) / 2\n",
    "    return round(x_center), round(y_center)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def centroid_distance(x1,y1,x2,y2):\n",
    "    return np.sqrt((x1-x2)**2 + (y1-y2)**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "draw_bounding_boxes = True\n",
    "draw_centroids = True\n",
    "draw_mid_line = True    \n",
    "draw_counts = True      # draw counts of cards\n",
    "vis = True              #visualize everything \n",
    "save_video = False\n",
    "\n",
    "abandoned_patience = 20 # how many frames to wait before centroid deleted\n",
    "minimum_distance = 50   # distance to consider two centroids (in consecutive frames) the same\n",
    "x_cutoff = 0.5          # line = x_res * this\n",
    "y_cutoff = 0.5          \n",
    "frameTime = 1           # delay between frames = how fast video showing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "abandoned_objects = {}\n",
    "def updateAbandoned(old_centroid_locations, object_locations):\n",
    "    # copy object_locations\n",
    "    object_locations_copy = object_locations.copy()\n",
    "    for ix, c in old_centroid_locations.items():\n",
    "        new_centroid = object_locations_copy[ix]\n",
    "        if new_centroid == old_centroid_locations[ix]:\n",
    "                if ix in abandoned_objects:\n",
    "                    abandoned_objects[ix] += 1\n",
    "                else:\n",
    "                    abandoned_objects[ix] = 1\n",
    "        else:\n",
    "            if ix in abandoned_objects:\n",
    "                abandoned_objects[ix] = 0\n",
    "            else:\n",
    "                abandoned_objects[ix] = 0\n",
    "    \n",
    "    for k, v in dict(abandoned_objects).items():\n",
    "        if v > abandoned_patience:\n",
    "            # print('Abandoned object:', k)\n",
    "            del abandoned_objects[k]\n",
    "            del object_locations[k]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "prev_total_count = 0\n",
    "def draw(frame, object_locations, left_right, right_left):\n",
    "    global prev_total_count\n",
    "    mid_x = round(frame.shape[1] * x_cutoff)\n",
    "    mid_y = round(frame.shape[0] * y_cutoff)\n",
    "    if vis:\n",
    "        # cv2 show centroids\n",
    "        if draw_centroids:\n",
    "            for id, c in object_locations.items():\n",
    "                cv2.circle(frame, (c[0], c[1]), 5, (0, 0, 255), -1)\n",
    "\n",
    "        if draw_counts:\n",
    "            # show right_left on left of frame\n",
    "            cv2.putText(frame, f'{right_left}', (100, 100),cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)\n",
    "\n",
    "            # show left_right on right of frame\n",
    "            cv2.putText(frame, f'{left_right}', (frame.shape[1] - 100, 100), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)\n",
    "\n",
    "            total_count = left_right + right_left\n",
    "            \n",
    "            # show total centred X\n",
    "            cv2.putText(frame, f'{total_count}', (frame.shape[1]//2, 100), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)\n",
    "\n",
    "        # draw vertical line in middle\n",
    "        if draw_mid_line:\n",
    "            if prev_total_count != total_count:\n",
    "                cv2.line(frame, (mid_x, 0), (mid_x, frame.shape[0]), (0, 0, 255), 2)\n",
    "            else:\n",
    "                cv2.line(frame, (round(frame.shape[1]*x_cutoff), 0), (round(frame.shape[1]*x_cutoff), frame.shape[0]), (0, 255, 0), 2)\n",
    "\n",
    "        prev_total_count = total_count\n",
    "        cv2.imshow('frame', frame)\n",
    "        if cv2.waitKey(frameTime) & 0xFF == ord('q'):\n",
    "            return False\n",
    "    return True, frame\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def updateCentroids(frame, object_locations, curr_centroids, left_right, right_left):\n",
    "    mid_x = round(frame.shape[1] * x_cutoff)\n",
    "    mid_y = round(frame.shape[0] * y_cutoff)\n",
    "         # match new centroids with old\n",
    "    old_centroid_locations = {k: v for k, v in object_locations.items()}\n",
    "    for ix, c in enumerate(curr_centroids):\n",
    "        if len(object_locations) == 0:\n",
    "            object_locations[ix] = c\n",
    "        else:\n",
    "            keys = list(object_locations.keys())\n",
    "            next_key = max(keys) + 1\n",
    "            min_centroid = next_key\n",
    "            for id, o in object_locations.items():\n",
    "                dist = centroid_distance(o[0], o[1], c[0], c[1])\n",
    "                min_dist = minimum_distance\n",
    "                if dist < min_dist:\n",
    "                    min_dist = dist\n",
    "                    min_centroid = id\n",
    "\n",
    "            if min_centroid != next_key:\n",
    "                old_centroid = object_locations[min_centroid]\n",
    "                if old_centroid[0] <= mid_x:\n",
    "                    if c[0] > mid_x:\n",
    "                        left_right += 1\n",
    "                elif old_centroid[0] >= mid_x:\n",
    "                    if c[0] < mid_x:\n",
    "                        right_left += 1\n",
    "\n",
    "            object_locations[min_centroid] = c\n",
    "    \n",
    "    return old_centroid_locations, object_locations, left_right, right_left\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getCentroids(annotations):\n",
    "    curr_centroids = []\n",
    "    for a in annotations:\n",
    "        a = a.split(' ')\n",
    "        a = [float(x) for x in a]\n",
    "        class_id = a[0]\n",
    "        a = a[1:]\n",
    "        x, y, w, h = a[0], a[1], a[2], a[3]\n",
    "        x1, y1, x2, y2 = convert_to_minmax(\n",
    "            x, y, w, h, (frame.shape[0], frame.shape[1]))\n",
    "        curr_centroids.append(find_centroid(x1, y1, x2, y2))\n",
    "\n",
    "        if vis and draw_bounding_boxes:\n",
    "                cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "\n",
    "    return curr_centroids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video: Day_1 Set: Test Frames: 467 Annotations: 467\n",
      "Video: Day_2 Set: Test Frames: 317 Annotations: 317\n",
      "Video: Dry Set: Test Frames: 324 Annotations: 324\n",
      "Video: Night_1 Set: Test Frames: 306 Annotations: 306\n",
      "Video: Night_2 Set: Test Frames: 321 Annotations: 321\n",
      "Video: Rain_1 Set: Test Frames: 314 Annotations: 314\n",
      "Video: Wet_Bright Set: Test Frames: 325 Annotations: 325\n",
      "Video: Wet_Dim Set: Test Frames: 317 Annotations: 317\n",
      "Video: Day_1 Set: Train Frames: 1025 Annotations: 1025\n",
      "Video: Day_2 Set: Train Frames: 924 Annotations: 924\n",
      "Video: Dry Set: Train Frames: 1202 Annotations: 1202\n",
      "Video: Night_1 Set: Train Frames: 1070 Annotations: 1070\n",
      "Video: Night_2 Set: Train Frames: 915 Annotations: 915\n",
      "Video: Rain_1 Set: Train Frames: 1057 Annotations: 1057\n",
      "Video: Wet_Bright Set: Train Frames: 1075 Annotations: 1075\n",
      "Video: Wet_Dim Set: Train Frames: 1205 Annotations: 1205\n"
     ]
    }
   ],
   "source": [
    "results = {'model': annotation_choice, 'videos': {}}\n",
    "\n",
    "for v in videos:\n",
    "    object_locations = {}\n",
    "    abandoned_objects = {}\n",
    "    left_right = 0\n",
    "    right_left = 0\n",
    "    \n",
    "    \n",
    "    video = cv2.VideoCapture(v)\n",
    "    video_name = v.split('\\\\')[-1].split('.')[0]\n",
    "    if 'val' in v.lower():\n",
    "        continue\n",
    "    if 'test' in v.lower(): set = 'Test'\n",
    "    if 'train' in v.lower(): set = 'Train'\n",
    "    # if set != 'Test':\n",
    "    #     continue\n",
    "    annotation_files = [a for a in annotation_paths if video_name.lower() in a.lower()]\n",
    "    annotation_files = [a for a in annotation_files if set.lower() in a.lower()]\n",
    "    sorted_annotation_files = sorted(annotation_files, key=lambda x: x.rsplit('.')[-2])\n",
    "\n",
    "\n",
    "    if save_video:\n",
    "        fourcc = cv2.VideoWriter_fourcc(*'XVID')\n",
    "        out = cv2.VideoWriter(f'{video_name}_{set}.avi', fourcc, 30.0, (round(video.get(3)), round(video.get(4))))\n",
    "\n",
    "    print(f'Video: {video_name} Set: {set} Frames: {int(video.get(cv2.CAP_PROP_FRAME_COUNT))} Annotations: {len(annotation_files)}')\n",
    "    while True:\n",
    "        ret, frame = video.read()\n",
    "        if not ret:\n",
    "            break\n",
    "       \n",
    "\n",
    "        curr_frame = int(video.get(cv2.CAP_PROP_POS_FRAMES))\n",
    "\n",
    "        # print(f'Frame: {curr_frame}')\n",
    "        annotation_file = annotation_files[curr_frame-1]\n",
    "        annotations = open(annotation_file, 'r')\n",
    "        annotations = annotations.readlines()\n",
    "        annotations = [a.strip() for a in annotations]\n",
    "\n",
    "        curr_centroids = getCentroids(annotations)\n",
    "        old_centroid_locations, object_locations, left_right, right_left = updateCentroids(frame, object_locations, curr_centroids, left_right, right_left)\n",
    "        updateAbandoned(old_centroid_locations, object_locations)\n",
    "        toContinue, drawn_frame = draw(frame, object_locations, left_right, right_left)\n",
    "        if save_video:\n",
    "            out.write(drawn_frame)\n",
    "        if not toContinue:\n",
    "            break\n",
    "        \n",
    "    results['videos'][video_name+'_'+set] = {'left_right': left_right, 'right_left': right_left, 'total': left_right + right_left}\n",
    "\n",
    "\n",
    "    cv2.destroyAllWindows()\n",
    "    video.release()\n",
    "\n",
    "# save results\n",
    "with open(f'{count_output_path}{annotation_choice}_results.json', 'w') as f:\n",
    "    json.dump(results, f, indent=4)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video: Day_1_Test Predicted: 1 Ground Truth: 2\n",
      "MAE: 1 MSE: 1\n",
      "Video: Day_2_Test Predicted: 0 Ground Truth: 0\n",
      "MAE: 0 MSE: 0\n",
      "Video: Dry_Test Predicted: 1 Ground Truth: 1\n",
      "MAE: 0 MSE: 0\n",
      "Video: Night_1_Test Predicted: 1 Ground Truth: 0\n",
      "MAE: 1 MSE: 1\n",
      "Video: Night_2_Test Predicted: 0 Ground Truth: 0\n",
      "MAE: 0 MSE: 0\n",
      "Video: Rain_1_Test Predicted: 3 Ground Truth: 3\n",
      "MAE: 0 MSE: 0\n",
      "Video: Wet_Bright_Test Predicted: 3 Ground Truth: 3\n",
      "MAE: 0 MSE: 0\n",
      "Video: Wet_Dim_Test Predicted: 1 Ground Truth: 2\n",
      "MAE: 1 MSE: 1\n",
      "Video: Day_1_Train Predicted: 10 Ground Truth: 3\n",
      "MAE: 7 MSE: 49\n",
      "Video: Day_2_Train Predicted: 0 Ground Truth: 0\n",
      "MAE: 0 MSE: 0\n",
      "Video: Dry_Train Predicted: 7 Ground Truth: 8\n",
      "MAE: 1 MSE: 1\n",
      "Video: Night_1_Train Predicted: 1 Ground Truth: 1\n",
      "MAE: 0 MSE: 0\n",
      "Video: Night_2_Train Predicted: 0 Ground Truth: 0\n",
      "MAE: 0 MSE: 0\n",
      "Video: Rain_1_Train Predicted: 14 Ground Truth: 8\n",
      "MAE: 6 MSE: 36\n",
      "Video: Wet_Bright_Train Predicted: 40 Ground Truth: 20\n",
      "MAE: 20 MSE: 400\n",
      "Video: Wet_Dim_Train Predicted: 9 Ground Truth: 5\n",
      "MAE: 4 MSE: 16\n",
      "--------------------------------------------------\n",
      "MAE: 2.5625 MSE: 31.5625\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# find mae and mse\n",
    "predicted_path = 'outputs\\counting\\ourYolo_results.json'\n",
    "ground_truth_path = 'outputs\\counting\\ground_truth_results.json'\n",
    "\n",
    "predicted_results = json.load(open(predicted_path, 'r'))['videos']\n",
    "ground_truth_results = json.load(open(ground_truth_path, 'r'))['videos']\n",
    "\n",
    "maes = []\n",
    "mse = []\n",
    "for video in predicted_results:\n",
    "    pred_total = predicted_results[video]['total']\n",
    "    gt_total = ground_truth_results[video]['total']\n",
    "    print(f'Video: {video} Predicted: {pred_total} Ground Truth: {gt_total}')\n",
    "    print(f'MAE: {abs(pred_total - gt_total)} MSE: {(pred_total - gt_total)**2}')\n",
    "    maes.append(abs(pred_total - gt_total))\n",
    "    mse.append((pred_total - gt_total)**2)\n",
    "    plt.plot(list(predicted_results.keys()).index(video), abs(pred_total - gt_total), 'ro')\n",
    "    plt.xlabel('Video Index')\n",
    "    plt.ylabel('MAE')\n",
    "\n",
    "    # plt.plot(abs(pred_total - gt_total), abs(gt_total), 'ro')\n",
    "    # plt.xlabel('MAE')\n",
    "    # plt.ylabel('Ground Truth Count')\n",
    "\n",
    "print('-'*50)\n",
    "print(f'MAE: {sum(maes)/len(maes)} MSE: {sum(mse)/len(mse)}')\n",
    "print('-'*50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "bda7da3f1f17f53873a773ca7f2ed74b2eb6ac96c2af17f2f610b1874751e508"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('CV': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
