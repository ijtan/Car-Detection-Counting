{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_dir = 'custom_train/datasets/OurDataSet/'\n",
    "clips_dir = 'inputs/media/Clips/'\n",
    "annotations_dir = 'inputs/annotations/'\n",
    "\n",
    "classes = ['car', 'motorcycle', 'truck', 'priority', 'bus']\n",
    "\n",
    "rel_dir = 'datasets/OurDataSet/'\n",
    "\n",
    "images_out_dir = out_dir + 'images/'\n",
    "labels_out_dir = out_dir + 'labels/'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "yam_dir = out_dir + 'OurDataset.yaml'\n",
    "train_dir = rel_dir + 'images/'+'train/'\n",
    "val_dir = rel_dir + 'images/' + 'val/'\n",
    "\n",
    "nc = len(classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "videos = list(Path(clips_dir).rglob('*.mp4'))\n",
    "videos = [str(v) for v in videos]\n",
    "# videos = [str(v) for v in videos if 'train' in str(v).lower()]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Day_1_Test: 100%|██████████| 467/467 [00:06<00:00, 75.88it/s] \n",
      "Processing Day_2_Test: 100%|██████████| 317/317 [00:04<00:00, 68.84it/s]\n",
      "Processing Dry_Test: 100%|██████████| 324/324 [00:03<00:00, 102.24it/s]\n",
      "Processing Night_1_Test: 100%|██████████| 306/306 [00:04<00:00, 62.00it/s]\n",
      "Processing Night_2_Test: 100%|██████████| 321/321 [00:04<00:00, 68.76it/s]\n",
      "Processing Rain_1_Test: 100%|██████████| 314/314 [00:01<00:00, 173.58it/s]\n",
      "Processing Wet_Bright_Test: 100%|██████████| 325/325 [00:03<00:00, 95.52it/s] \n",
      "Processing Wet_Dim_Test: 100%|██████████| 317/317 [00:03<00:00, 80.60it/s]\n",
      "Processing Day_1_Train: 100%|██████████| 1025/1025 [00:14<00:00, 68.52it/s] \n",
      "Processing Day_2_Train: 100%|██████████| 924/924 [00:13<00:00, 66.11it/s]\n",
      "Processing Dry_Train: 100%|██████████| 1202/1202 [00:11<00:00, 102.72it/s]\n",
      "Processing Night_1_Train: 100%|██████████| 1070/1070 [00:16<00:00, 63.16it/s]\n",
      "Processing Night_2_Train: 100%|██████████| 915/915 [00:14<00:00, 62.39it/s]\n",
      "Processing Rain_1_Train: 100%|██████████| 1057/1057 [00:06<00:00, 172.02it/s]\n",
      "Processing Wet_Bright_Train: 100%|██████████| 1075/1075 [00:10<00:00, 98.35it/s] \n",
      "Processing Wet_Dim_Train: 100%|██████████| 1205/1205 [00:10<00:00, 109.56it/s]\n",
      "Processing Day_1_Test: 100%|██████████| 467/467 [00:06<00:00, 74.13it/s] \n",
      "Processing Day_2_Test: 100%|██████████| 317/317 [00:06<00:00, 51.02it/s]\n",
      "Processing Dry_Test: 100%|██████████| 324/324 [00:03<00:00, 83.25it/s]\n",
      "Processing Night_1_Test: 100%|██████████| 306/306 [00:05<00:00, 56.96it/s]\n",
      "Processing Night_2_Test: 100%|██████████| 321/321 [00:05<00:00, 58.19it/s]\n",
      "Processing Rain_1_Test: 100%|██████████| 314/314 [00:02<00:00, 149.02it/s]\n",
      "Processing Wet_Bright_Test: 100%|██████████| 325/325 [00:03<00:00, 83.86it/s]\n",
      "Processing Wet_Dim_Test: 100%|██████████| 317/317 [00:03<00:00, 81.46it/s]\n",
      "Processing Day_1_Train: 100%|██████████| 1025/1025 [00:12<00:00, 80.35it/s] \n",
      "Processing Day_2_Train: 100%|██████████| 924/924 [00:17<00:00, 52.59it/s]\n",
      "Processing Dry_Train: 100%|██████████| 1202/1202 [00:15<00:00, 77.49it/s]\n",
      "Processing Night_1_Train: 100%|██████████| 1070/1070 [00:18<00:00, 56.35it/s]\n",
      "Processing Night_2_Train: 100%|██████████| 915/915 [00:16<00:00, 54.60it/s]\n",
      "Processing Rain_1_Train: 100%|██████████| 1057/1057 [00:07<00:00, 145.23it/s]\n",
      "Processing Wet_Bright_Train: 100%|██████████| 1075/1075 [00:12<00:00, 83.95it/s]\n",
      "Processing Wet_Dim_Train: 100%|██████████| 1205/1205 [00:14<00:00, 81.56it/s]\n",
      "Processing Day_1_Val: 100%|██████████| 305/305 [00:03<00:00, 93.90it/s] \n",
      "Processing Day_2_Val: 100%|██████████| 310/310 [00:06<00:00, 49.11it/s]\n",
      "Processing Dry_Val: 100%|██████████| 324/324 [00:06<00:00, 46.36it/s]\n",
      "Processing Night_1_Val: 100%|██████████| 322/322 [00:08<00:00, 39.28it/s]\n",
      "Processing Night_2_Val: 100%|██████████| 311/311 [00:07<00:00, 41.98it/s]\n",
      "Processing Rain_1_Val: 100%|██████████| 311/311 [00:04<00:00, 76.63it/s]\n",
      "Processing Wet_Bright_Val: 100%|██████████| 325/325 [00:06<00:00, 52.45it/s]\n",
      "Processing Wet_Dim_Val: 100%|██████████| 317/317 [00:05<00:00, 54.70it/s]\n"
     ]
    }
   ],
   "source": [
    "train_paths = []\n",
    "val_paths = []\n",
    "\n",
    "for video in videos:\n",
    "    # print(video)\n",
    "    extension = ''\n",
    "    if 'train' in video.lower():\n",
    "        extension = '_Train'\n",
    "    elif 'test' in video.lower():\n",
    "        extension = '_Test'\n",
    "    elif 'valid' in video.lower():\n",
    "        extension = '_Val'\n",
    "\n",
    "    vid_dir = video.replace('.mp4', extension)\n",
    "\n",
    "    vid_dir = vid_dir.split('\\\\')[-1].split('/')[-1]\n",
    "    annotations_paths = [str(v) for v in list(Path(annotations_dir+vid_dir).rglob('*.txt'))]\n",
    "\n",
    "    cap = cv2.VideoCapture(video)\n",
    "    n_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "    # print(fps)\n",
    "    # print(n_frames)\n",
    "    for i in tqdm(range(n_frames), desc='Processing '+vid_dir):\n",
    "        ret, frame = cap.read()\n",
    "        if ret:\n",
    "            # creaye dir if not exist\n",
    "            if not Path(images_out_dir+vid_dir).exists():\n",
    "                Path(images_out_dir+vid_dir).mkdir(parents=True)\n",
    "            \n",
    "            # ensure frame is no zero size array\n",
    "            if frame.shape[0] == 0 or frame.shape[1] == 0 or frame.size == 0:\n",
    "                print('SKIPPING ERRORED FRAME: ', vid_dir, i)\n",
    "                continue\n",
    "            \n",
    "            contents = open(annotations_paths[i], 'r').readlines()\n",
    "            if len(contents) == 0:\n",
    "                continue\n",
    "            \n",
    "            if not Path(labels_out_dir + vid_dir).exists():\n",
    "                Path(labels_out_dir + vid_dir).mkdir(parents=True)\n",
    "\n",
    "            dest_path = labels_out_dir + vid_dir+'/' + str(i) + '.txt'\n",
    "            with open(dest_path, 'w') as f:\n",
    "                f.writelines(contents)\n",
    "\n",
    "            cv2.imwrite(images_out_dir + vid_dir+'/' + str(i) + '.jpg', frame)\n",
    "\n",
    "        else:\n",
    "            print('error')\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_paths = []\n",
    "val_paths = []\n",
    "\n",
    "full_images = out_dir + 'images/'\n",
    "full_labels = out_dir + 'labels/'\n",
    "\n",
    "all_image_dirs = os.listdir(full_images)\n",
    "all_train_images = [i for i in all_image_dirs if 'train' in i.lower()]\n",
    "all_test_images = [i for i in all_image_dirs if 'test' in i.lower()]\n",
    "all_val_images = [i for i in all_image_dirs if 'val' in i.lower()]\n",
    "\n",
    "all_train_images\n",
    "\n",
    "path = '../datasets/OurDataSet/'\n",
    "im_dir ='images/'\n",
    "lab_dir = 'labels/'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "49"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yam_file = open(yam_dir, 'w')\n",
    "yam_file.write('# This file is automatically generated by dataSetter.py\\n')\n",
    "# yam_file.write('train: ' + train_dir + '\\n')\n",
    "# yam_file.write('val: ' + val_dir + '\\n')\n",
    "\n",
    "yam_file.write('path: ' + path + '\\n')\n",
    "yam_file.write('train: ' + '\\n')\n",
    "for dir in all_train_images:\n",
    "    yam_file.write('  - '+im_dir+dir+'\\n')\n",
    "if len(all_val_images) > 0:\n",
    "    yam_file.write('val: ' + '\\n')\n",
    "    for dir in all_val_images:\n",
    "        yam_file.write('  - '+im_dir+dir+'\\n')\n",
    "yam_file.write('\\n')\n",
    "if len(all_test_images) > 0:\n",
    "    yam_file.write('test: ' + '\\n')\n",
    "    for dir in all_test_images:\n",
    "        yam_file.write('  - '+im_dir+dir+'\\n')\n",
    "\n",
    "yam_file.write('\\n')\n",
    "\n",
    "\n",
    "yam_file.write('# number of classes\\n')\n",
    "yam_file.write('nc: ' + str(nc) + '\\n')\n",
    "yam_file.write('\\n')\n",
    "yam_file.write('# class names\\n')\n",
    "yam_file.write('names: ')\n",
    "yam_file.write('[' + '\\'' + '\\', \\''.join(classes) + '\\'' + ']')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "bda7da3f1f17f53873a773ca7f2ed74b2eb6ac96c2af17f2f610b1874751e508"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('CV': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
