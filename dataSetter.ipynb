{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_dir = 'custom_train/datasets/OurDataSet/'\n",
    "clips_dir = 'inputs/media/Clips/'\n",
    "annotations_dir = 'inputs/annotations/'\n",
    "\n",
    "classes = ['car', 'motorcycle', 'truck', 'priority', 'bus']\n",
    "\n",
    "rel_dir = 'datasets/OurDataSet/'\n",
    "\n",
    "images_out_dir = out_dir + 'images/'\n",
    "labels_out_dir = out_dir + 'labels/'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "yam_dir = out_dir + 'OurDataset.yaml'\n",
    "train_dir = rel_dir + 'images/'+'train/'\n",
    "val_dir = rel_dir + 'images/' + 'val/'\n",
    "\n",
    "nc = len(classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "videos = list(Path(clips_dir).rglob('*.mp4'))\n",
    "videos = [str(v) for v in videos]\n",
    "# videos = [str(v) for v in videos if 'train' in str(v).lower()]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Day_1_Test: 100%|██████████| 467/467 [00:09<00:00, 49.66it/s]\n",
      "Processing Day_2_Test: 100%|██████████| 317/317 [00:07<00:00, 44.55it/s]\n",
      "Processing Dry_Test: 100%|██████████| 324/324 [00:05<00:00, 58.32it/s]\n",
      "Processing Night_1_Test: 100%|██████████| 306/306 [00:07<00:00, 40.49it/s]\n",
      "Processing Night_2_Test: 100%|██████████| 321/321 [00:07<00:00, 42.09it/s]\n",
      "Processing Rain_1_Test: 100%|██████████| 314/314 [00:04<00:00, 75.25it/s]\n",
      "Processing Wet_Bright_Test: 100%|██████████| 325/325 [00:05<00:00, 60.76it/s]\n",
      "Processing Wet_Dim_Test: 100%|██████████| 317/317 [00:03<00:00, 98.29it/s] \n",
      "Processing Day_1_Train: 100%|██████████| 1025/1025 [00:18<00:00, 55.94it/s]\n",
      "Processing Day_2_Train: 100%|██████████| 924/924 [00:19<00:00, 47.38it/s]\n",
      "Processing Dry_Train: 100%|██████████| 1202/1202 [00:19<00:00, 62.02it/s]\n",
      "Processing Night_1_Train: 100%|██████████| 1070/1070 [00:21<00:00, 49.06it/s]\n",
      "Processing Night_2_Train: 100%|██████████| 915/915 [00:21<00:00, 42.45it/s]\n",
      "Processing Rain_1_Train: 100%|██████████| 1057/1057 [00:13<00:00, 78.62it/s]\n",
      "Processing Wet_Bright_Train: 100%|██████████| 1075/1075 [00:15<00:00, 69.78it/s]\n",
      "Processing Wet_Dim_Train: 100%|██████████| 1205/1205 [00:19<00:00, 61.88it/s]\n",
      "Processing Day_1_Test: 100%|██████████| 467/467 [00:08<00:00, 55.90it/s]\n",
      "Processing Day_2_Test: 100%|██████████| 317/317 [00:06<00:00, 51.97it/s]\n",
      "Processing Dry_Test: 100%|██████████| 324/324 [00:04<00:00, 74.80it/s]\n",
      "Processing Night_1_Test: 100%|██████████| 306/306 [00:05<00:00, 51.23it/s]\n",
      "Processing Night_2_Test: 100%|██████████| 321/321 [00:05<00:00, 55.91it/s]\n",
      "Processing Rain_1_Test: 100%|██████████| 314/314 [00:02<00:00, 151.54it/s]\n",
      "Processing Wet_Bright_Test: 100%|██████████| 325/325 [00:03<00:00, 84.18it/s]\n",
      "Processing Wet_Dim_Test: 100%|██████████| 317/317 [00:03<00:00, 83.37it/s]\n",
      "Processing Day_1_Train: 100%|██████████| 1025/1025 [00:16<00:00, 61.95it/s]\n",
      "Processing Day_2_Train: 100%|██████████| 924/924 [00:17<00:00, 52.00it/s]\n",
      "Processing Dry_Train: 100%|██████████| 1202/1202 [00:15<00:00, 79.67it/s]\n",
      "Processing Night_1_Train: 100%|██████████| 1070/1070 [00:18<00:00, 56.69it/s]\n",
      "Processing Night_2_Train: 100%|██████████| 915/915 [00:16<00:00, 55.50it/s]\n",
      "Processing Rain_1_Train: 100%|██████████| 1057/1057 [00:07<00:00, 148.72it/s]\n",
      "Processing Wet_Bright_Train: 100%|██████████| 1075/1075 [00:12<00:00, 82.91it/s]\n",
      "Processing Wet_Dim_Train: 100%|██████████| 1205/1205 [00:14<00:00, 82.59it/s]\n"
     ]
    }
   ],
   "source": [
    "train_paths = []\n",
    "val_paths = []\n",
    "\n",
    "for video in videos:\n",
    "    # print(video)\n",
    "    extension = ''\n",
    "    if 'train' in video.lower():\n",
    "        extension = '_Train'\n",
    "    elif 'test' in video.lower():\n",
    "        extension = '_Test'\n",
    "\n",
    "    vid_dir = video.replace('.mp4', extension)\n",
    "\n",
    "    vid_dir = vid_dir.split('\\\\')[-1].split('/')[-1]\n",
    "    annotations_paths = [str(v) for v in list(Path(annotations_dir+vid_dir).rglob('*.txt'))]\n",
    "\n",
    "    cap = cv2.VideoCapture(video)\n",
    "    n_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "    # print(fps)\n",
    "    # print(n_frames)\n",
    "    for i in tqdm(range(n_frames), desc='Processing '+vid_dir):\n",
    "        ret, frame = cap.read()\n",
    "        if ret:\n",
    "            # creaye dir if not exist\n",
    "            if not Path(images_out_dir+vid_dir).exists():\n",
    "                Path(images_out_dir+vid_dir).mkdir(parents=True)\n",
    "            cv2.imwrite(images_out_dir + vid_dir+'/' + str(i) + '.jpg', frame)\n",
    "            # cv2.imshow('frame', frame)\n",
    "\n",
    "            with open(annotations_paths[i]) as f:\n",
    "                if len(f.readlines()) == 0:\n",
    "                    continue\n",
    "                \n",
    "                # if sub_folder does not exist create it\n",
    "                if not Path(labels_out_dir + vid_dir).exists():\n",
    "                    Path(labels_out_dir + vid_dir).mkdir(parents=True)\n",
    "\n",
    "                with open(labels_out_dir + vid_dir+'/' + str(i) + '.txt', 'w') as destination:\n",
    "                    for line in f:\n",
    "                        destination.write(line)\n",
    "\n",
    "        else:\n",
    "            print('error')\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_paths = []\n",
    "val_paths = []\n",
    "\n",
    "full_images = out_dir + 'images/'\n",
    "full_labels = out_dir + 'labels/'\n",
    "\n",
    "all_image_dirs = os.listdir(full_images)\n",
    "all_train_images = [i for i in all_image_dirs if 'train' in i.lower()]\n",
    "all_val_images = [i for i in all_image_dirs if 'test' in i.lower()]\n",
    "\n",
    "all_train_images\n",
    "\n",
    "path = '../datasets/OurDataSet/'\n",
    "im_dir ='images/'\n",
    "lab_dir = 'labels/'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "49"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yam_file = open(yam_dir, 'w')\n",
    "yam_file.write('# This file is automatically generated by dataSetter.py\\n')\n",
    "# yam_file.write('train: ' + train_dir + '\\n')\n",
    "# yam_file.write('val: ' + val_dir + '\\n')\n",
    "\n",
    "yam_file.write('path: ' + path + '\\n')\n",
    "yam_file.write('train: ' + '\\n')\n",
    "for dir in all_train_images:\n",
    "    yam_file.write('  - '+im_dir+dir+'\\n')\n",
    "if len(all_val_images) > 0:\n",
    "    yam_file.write('val: ' + '\\n')\n",
    "    for dir in all_val_images:\n",
    "        yam_file.write('  - '+im_dir+dir+'\\n')\n",
    "yam_file.write('\\n')\n",
    "\n",
    "\n",
    "yam_file.write('# number of classes\\n')\n",
    "yam_file.write('nc: ' + str(nc) + '\\n')\n",
    "yam_file.write('\\n')\n",
    "yam_file.write('# class names\\n')\n",
    "yam_file.write('names: ')\n",
    "yam_file.write('[' + '\\'' + '\\', \\''.join(classes) + '\\'' + ']')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "bda7da3f1f17f53873a773ca7f2ed74b2eb6ac96c2af17f2f610b1874751e508"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('CV': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
